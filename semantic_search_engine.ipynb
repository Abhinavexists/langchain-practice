{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain's document loader, embedding, and vector store abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if os.environ[\"LANGSMITH_API_KEY\"] not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents and Document Loaders\n",
    "\n",
    "LangChain implements a Document abstraction, which is intended to represent a unit of text and associated metadata. It has three attributes:\n",
    "\n",
    "```page_content```: a string representing the content;\n",
    "\n",
    "```metadata```: a dict containing arbitrary metadata;\n",
    "\n",
    "```id```: (optional) a string identifier for the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata = {\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata = {\"source\": \"mammal-pets-doc\"},\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"nke-10k-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑  ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "F\n",
      "\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[0].page_content[:200]}\\n\")\n",
    "print(f\"{docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, chunk_overlap = 200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "len(all_splits)\n",
    "\n",
    "# set add_start_index=True so that the character index where each split Document\n",
    "# starts within the initial Document is preserved as metadata attribute “start_index”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "Vector search is a common way to store and search over unstructured data (such as unstructured text). The idea is to store numeric vectors that are associated with the text. Given a query, we can embed it as a vector of the same dimension and use vector similarity metrics (such as cosine similarity) to identify related text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There can be these warning\n",
    " \n",
    "# IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "# UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
    "#   warnings.warn(\n",
    "\n",
    "# To resolve these issue\n",
    "# pip install --upgrade jupyter ipywidgets\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"MISTRAL_API_KEY\"):\n",
    "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter API key for MistralAI: \")\n",
    "\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of Length 1024\n",
      "\n",
      "[-0.0029048919677734375, 0.038848876953125, 0.03326416015625, -0.01450347900390625, 0.01552581787109375, 0.03680419921875, 0.02630615234375, -0.0110321044921875, 0.0010709762573242188, 0.0011987686157226562]\n"
     ]
    }
   ],
   "source": [
    "vector1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "# embeddings.embed_query(text) converts the text into an embedding\n",
    "# (a numerical vector representation)\n",
    "assert len(vector1) == len(vector2)\n",
    "# ensures that both embeddings have the same length.\n",
    "print(f\"Generated vectors of Length {len(vector1)}\\n\")\n",
    "print(vector1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Stores\n",
    "LangChain VectorStore objects contain methods for adding text and Document objects to the store, and querying them using various similarity metrics. They are often initialized with embedding models, which determine how text data is translated to numeric vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres import PGVector\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"my_docs\",\n",
    "    connection=\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
